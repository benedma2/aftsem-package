{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c5b3c6-ed69-42d6-8e78-e99a5a939648",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92d93a-27a0-4a79-9dd6-2b8cc78bb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"extRemes\") # for generating data\n",
    "#install.packages(\"ggplot2\") # for plotting results\n",
    "#install.packages(\"dplyr\") # for printing summary tables\n",
    "#install.packages(\"tidyr\") \n",
    "#install.packages(\"knitr\")\n",
    "#install.packages(\"IRdisplay\") # nicer print in jupyter-lab\n",
    "#install.packages(\"tibble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a36e7-1d82-44fd-97b3-2e46d1ef1452",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09aa52-b839-48af-b9b7-968a021add69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(aftsem)\n",
    "# you should load aftsem before survival, otherwise one might expect conflicts in packages\n",
    "library(survival)\n",
    "library(extRemes) # for data generation\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(knitr)\n",
    "library(IRdisplay)\n",
    "library(tibble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d558a0-0821-4798-b39e-9a25cc328b97",
   "metadata": {},
   "source": [
    "### About experiments\n",
    "\n",
    "The results of different experiments are stored as RDS files. Be careful when starting the experiment, you may need to change the RDS file name, otherwise you would rewrite the result of older simulation. Some results are stored in exp folder, you can use them for investigating or for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd83f63-3dac-475b-a1b8-6ae1b385fc6b",
   "metadata": {},
   "source": [
    "### Dataset generator\n",
    "This function provide user with simple dataset generator that takes three parameters\n",
    "<ul>\n",
    "    <li>n = number of samples/observations</li>\n",
    "    <li>error = error of epsilons</li>\n",
    "    <li>censor = percent of censoring in dataset (more about this later in simulation functions)</li>\n",
    "</ul>\n",
    "\n",
    "The final model looks like this: <b>logT = 2 + x1 + x2 + x3 + eps</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441b298-a9e5-4854-bb48-4adf972a4f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datgen_model1 <- function(n = 50, error = \"normal\", censor = 40)\n",
    "{\n",
    "    \n",
    "  x1 <- rbinom(n, 1, 0.5) # p = 0.5\n",
    "  x2 <- rnorm(n) # standard\n",
    "  x3 <- rnorm(n) # standard\n",
    "  \n",
    "  e <- numeric(n)\n",
    "  \n",
    "  if (error == \"normal\")\n",
    "  {\n",
    "    e <- rnorm(n)\n",
    "  }\n",
    "  else if (error == \"extreme\")\n",
    "  {\n",
    "    e <- revd(n, loc = 0, scale = 1, shape = 0)\n",
    "  }\n",
    "  else if (error == \"logistic\") \n",
    "  {\n",
    "    e <- rlogis(n, location = 0, scale = 1)\n",
    "  }\n",
    "  \n",
    "  \n",
    "  time <- exp(2 + x1 + x2 + x3 + e) # compute the censoring times\n",
    "  \n",
    "  if(censor == -1) cen <- rep(10^4,n) # if not censoring, manualy generate extremely large numbers\n",
    "  else  cen <- runif(n, 0, censor)\n",
    "  \n",
    "  # return the data frame with observed time, censoring status, covariates, and ID\n",
    "  data.frame(Time = pmin(time, cen), status = 1 * (time <= cen), x1 = x1, x2 = x2, x3 =x3, id = 1:n, error = error, censor = censor)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e4bdc-d324-40c6-818e-e64a6f410987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data <- datgen_model1(n=400,error=\"normal\",censor=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeee8b8-cdf7-44dc-b8be-13957412e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- 100000\n",
    "data_revd <- revd(n, loc = 0, scale = 1, shape = 0)\n",
    "data_logis <- rlogis(n,location = 0, scale = 1)\n",
    "data_normal <- rnorm(n)\n",
    "\n",
    "df_revd <- data.frame(value = data_revd, Rozdělení = 'Extrémní')\n",
    "df_logis <- data.frame(value = data_logis, Rozdělení = 'Logistické')\n",
    "df_normal <- data.frame(value = data_normal, Rozdělení = 'Normální')\n",
    "\n",
    "df_combined <- rbind(df_revd, df_logis, df_normal)\n",
    "\n",
    "# Plot the densities\n",
    "pp <- ggplot(df_combined, aes(x = value, color = Rozdělení)) +\n",
    "  geom_density(alpha = 0.3, size = 0.8) +  # Adjust transparency with alpha and line size\n",
    "  labs(title = \"Hustoty rozdělení\", x = \"Hodnota\", y = \"Hustota\") +\n",
    "  theme_minimal() +  # Minimal theme\n",
    "  scale_color_manual(values = c(\"Extrémní\" = \"blue\", \"Logistické\" = \"red\", \"Normální\" = \"green\" ))  # Colors\n",
    "print(pp)\n",
    "ggsave(\"density_plot.png\", pp, width = 10, height = 6, dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a53e0-8199-4740-8756-98ec91c93256",
   "metadata": {},
   "source": [
    "## Create seed file\n",
    "Necessary for reproducibility. The file is already generated, user just need to load the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b8bc8-7013-45f7-bf3e-8a2adbcfa889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set.seed(54)\n",
    "#write(sample(1:10000000,size=1000),file=\"seeds.txt\",ncolumns=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a1696-2ab8-48f4-ad2a-6e3a4815cd88",
   "metadata": {},
   "source": [
    "#### Load seed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41e52e-9c08-4af5-a1c4-65acb37d395a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds<-read.table(\"seeds.txt\",header=F)$V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65784fee-f7dd-4da1-ad75-02236993aab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_coefficients <- c(1,1,1) # setup the true coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7067eaa-3618-4d2b-848f-47fe7cfd6b87",
   "metadata": {},
   "source": [
    "## Simulation Config\n",
    "Simulation config for first experiment, we are interested in precision and effectivility of programmed methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c54bd-f2d7-437a-a17b-77eb04466103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_types <- c(\"normal\",\"extreme\",\"logistic\") # all available\n",
    "methods <- c(\"gehan\", \"gehan-poly\", \"gehan-heller\",\"jin\") # all available\n",
    "censoring <- c(0,25,50,90) # all available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1350a-c4fb-4e9b-854d-87e2e38575b0",
   "metadata": {},
   "source": [
    "### Bias, MSE and avg Time simulation study on all methods\n",
    "The function takes two parameters\n",
    "<ul>\n",
    "    <li>n_simulations = number of simulations</li>\n",
    "    <li>sample_size = number of observations in dataset</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03833c08-7720-437e-9360-a6c1b65de829",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sim <- function(n_simulations, sample_size)\n",
    "{ \n",
    "    time_results <- list() # for storing time results\n",
    "    results <- list() # for storing BIAS and MSE results\n",
    "    estimates_sim <- list() # for storing estimated regression parameters\n",
    "    fe_results <- list() # for storing number of calls to functions gehan-poly and gehan-heller, see optimx documentation for more info\n",
    "    \n",
    "    n_simulations <- n_simulations\n",
    "    sample_size <- sample_size\n",
    "\n",
    "    # Iterate through all different scenarios\n",
    "    for (error in error_types)\n",
    "    {\n",
    "      for (censor in censoring)\n",
    "          {\n",
    "              for (method in methods)\n",
    "              { \n",
    "                estimates <- matrix(NA, nrow = n_simulations, ncol = length(true_coefficients)) # to store estimated coefficients\n",
    "                times <- numeric(n_simulations) # to store elapsed time\n",
    "                fe_calls <- numeric(n_simulations) # to store function calls  \n",
    "\n",
    "                for (i in 1:n_simulations)\n",
    "                {\n",
    "                  # Generate data\n",
    "                  set.seed(seeds[i])\n",
    "\n",
    "                  censorNEW <- NaN # we need to adjust parameter of uniform distribution manualy\n",
    "                  \n",
    "                  if(censor == 0) {censorNEW <- -1} \n",
    "                  if(censor == 25){censorNEW <- 100} \n",
    "                  if(censor == 50) {censorNEW <- 30}\n",
    "                  if(censor == 90) {censorNEW <- 3}\n",
    "                    \n",
    "                  # chosen numbers of censorNEW are adjusted manualy, they give the desired percent of censoring  \n",
    "                    \n",
    "                  data <- datgen_model1(n = sample_size, error = error, censor = censorNEW)\n",
    "\n",
    "                  # measure time of model fitting\n",
    "                  time_taken <- system.time({\n",
    "                    fit <- aftsem(Surv(log(data$Time), data$status) ~ data$x1 + data$x2 + data$x3, method = method)\n",
    "                    estimates[i, ] <- c(fit$beta)\n",
    "                    if(method %in% c(\"gehan-heller\",\"gehan-poly\")) fe_calls[i] <- fit$fe  \n",
    "                  })\n",
    "\n",
    "                  # store elapsed time\n",
    "                  times[i] <- time_taken[3]\n",
    "                }\n",
    "\n",
    "                bias <- colMeans(estimates) - true_coefficients\n",
    "                mse <- colMeans((estimates - true_coefficients)^2)\n",
    "                avg_fe_calls <- mean(fe_calls)\n",
    "                avg_time <- mean(times)\n",
    "\n",
    "                results[[paste(error, method, censor, sep = \"_\")]] <- list(bias = bias, mse = mse)\n",
    "                time_results[[paste(error, method, censor, sep = \"_\")]] <- avg_time\n",
    "                fe_results[[paste(error, method, censor, sep = \"_\")]] <- avg_fe_calls\n",
    "                estimates_sim[[paste(error, method, censor, sep = \"_\")]] <- estimates\n",
    "              }\n",
    "        }\n",
    "    }\n",
    "    # save our simulations into RDS file, change if necessary\n",
    "    saveRDS(time_results, paste(\"time_results\", sample_size,\"2\", \".rds\", sep = \"_\"))\n",
    "    saveRDS(results, paste(\"results\",sample_size,\"2\",\".rds\", sep = \"_\"))\n",
    "    saveRDS(estimates_sim, paste(\"estimates_sim\",sample_size,\"2\",\".rds\", sep = \"_\"))\n",
    "    saveRDS(fe_results, paste(\"fe_results\",sample_size,\"2\",\".rds\",sep = \"_\"))\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3440a-8d30-4dc8-904a-8a295cfb02dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_sim(n_simulations = 1000, sample_size = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ef399-2237-4104-b352-7196f1743977",
   "metadata": {},
   "source": [
    "### See the results\n",
    "This creates nice summary dataframe that contains BIAS,MSE and Avg_time info. The data needs to be stored under names results and time_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33252d68-bd73-41ba-b0da-f26c98a0c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results <- readRDS(\"results_400_.rds\")\n",
    "# time_results <- readRDS(\"time_results_400_.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb1d5e-d549-4f3f-9739-0f84be6e2261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df <- do.call(rbind, lapply(names(results), function(name) {\n",
    "  data.frame(\n",
    "    Scenario = name,\n",
    "    Bias = results[[name]]$bias,\n",
    "    MSE = results[[name]]$mse,\n",
    "    Avg_Time = time_results[[name]]\n",
    "  )\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbf669-e4d1-41e1-ad03-b81c0e33190d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows = 150, repr.matrix.max.cols = 10) # if we want to see the whole dataframe\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e649f41-174e-46ab-a5b6-01615cbcbdd1",
   "metadata": {},
   "source": [
    "### Plot our results\n",
    "This function plots our estimated regression coefficients. The function plots chosen coefficients of all methods, where on the y-axis is ploted Gehan result and on the x-axis are ploted Heller,Poly and Jin. The function takes 4 parameters\n",
    "<ul>\n",
    "    <li>estimates = file with estimated regression parameters (for example estimates_sim_100_.rds</li>\n",
    "    <li>column_number = which of the beta we want to plot (1,2 or 3)</li>\n",
    "    <li>percen_censoring = which censoring scenario we want to plot</li>\n",
    "    <li>distribution_name = which epsilon error scenario we want to plot</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f81360-1197-4aec-869e-6643e91f0fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_estimates <- function(estimates, column_number, percent_censoring, distribution_name)\n",
    "{\n",
    "\n",
    "  # locate our data\n",
    "  gehan_key <- paste(distribution_name, \"gehan\", percent_censoring, sep = \"_\")\n",
    "  gehan_heller_key <- paste(distribution_name, \"gehan-heller\", percent_censoring, sep = \"_\")\n",
    "  gehan_poly_key <- paste(distribution_name, \"gehan-poly\", percent_censoring, sep = \"_\")\n",
    "  jin_key <-   paste(distribution_name, \"jin\", percent_censoring, sep = \"_\")\n",
    "  \n",
    "  # create data for plotting\n",
    "  gehan_data <- estimates[[gehan_key]][, column_number]\n",
    "  gehan_heller_data <- estimates[[gehan_heller_key]][, column_number]\n",
    "  gehan_poly_data <- estimates[[gehan_poly_key]][, column_number]\n",
    "  jin_data <- estimates[[jin_key]][,column_number]  \n",
    "  \n",
    "  # First plot: Gehan vs. Gehan-Heller\n",
    "  df_gehan_heller <- data.frame(Gehan = gehan_data, GehanHeller = gehan_heller_data)\n",
    "  p1 <- ggplot(df_gehan_heller, aes(x = GehanHeller, y = Gehan)) +\n",
    "    geom_point(alpha = 0.5) +\n",
    "    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\") +\n",
    "    xlab(\"Gehan-Heller\") +\n",
    "    ylab(\"Gehan\") +\n",
    "    ggtitle(paste(\"Gehan vs. Gehan-Heller\", \n",
    "                  \"(Cenzorovani:\", percent_censoring, \"%,\", distribution_name, \")\"))\n",
    "  \n",
    "  # Second plot: Gehan vs. Gehan-Poly\n",
    "  df_gehan_poly <- data.frame(Gehan = gehan_data, GehanPoly = gehan_poly_data)\n",
    "  p2 <- ggplot(df_gehan_poly, aes(x = GehanPoly, y = Gehan)) +\n",
    "    geom_point(alpha = 0.5) +\n",
    "    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\") +\n",
    "    xlab(\"Gehan-Poly\") +\n",
    "    ylab(\"Gehan\") +\n",
    "    ggtitle(paste(\"Gehan vs. Gehan-Poly\", \n",
    "                  \"(Cenzorovani:\", percent_censoring, \"%,\", distribution_name, \")\"))\n",
    "    \n",
    "  df_jin <- data.frame(Gehan = gehan_data, Jin = jin_data)   \n",
    "  p3 <- ggplot(df_gehan_poly, aes(x = GehanPoly, y = Gehan)) +\n",
    "    geom_point(alpha = 0.5) +\n",
    "    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\") +\n",
    "    xlab(\"Jin\") +\n",
    "    ylab(\"Gehan\") +\n",
    "    ggtitle(paste(\"Gehan vs. Jin\", \n",
    "                  \"(Cenzorovani:\", percent_censoring, \"%,\", distribution_name, \")\"))\n",
    " \n",
    "    \n",
    "  # save and print  \n",
    "  ggsave(filename = paste0(\"plot_Gehan_vs_Gehan-Heller_4\", distribution_name, \"_\", percent_censoring, \".png\"), plot = p1)\n",
    "  ggsave(filename = paste0(\"plot_Gehan_vs_Gehan-Poly_4\", distribution_name, \"_\", percent_censoring, \".png\"), plot = p2)\n",
    "  ggsave(filename = paste0(\"plot_Gehan_vs_Gehan vs. Jin_4\", distribution_name, \"_\", percent_censoring, \".png\"), plot = p3)\n",
    "  print(p1)\n",
    "  print(p2)\n",
    "  print(p3)\n",
    "}\n",
    "\n",
    "\n",
    "plot_estimates(estimates, 2, 50, 'normal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e8e8b-6729-4e50-925d-5c73bd0db55d",
   "metadata": {},
   "source": [
    "### Plot time results\n",
    "Plot time results from previous experiment. The function expect one parameter\n",
    "<ul>\n",
    "    <li>data_list=time_result list from first experimet </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dafbe5-232a-40e1-ac1f-cb75f0f46af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time <- function(data_list)\n",
    "{    \n",
    "    # first convert our list to dataframe using pipes\n",
    "    data <- enframe(data_list, name = \"metric\", value = \"value\") %>%\n",
    "    mutate(\n",
    "        metric = as.character(metric),\n",
    "        distribution = gsub(\"([a-z]+)_.*\", \"\\\\1\", metric),\n",
    "        method = gsub(\"[a-z]+_(.*?)(_\\\\d+)?$\", \"\\\\1\", metric),\n",
    "        percent_censoring = as.numeric(gsub(\".*_(\\\\d+)$\", \"\\\\1\", metric)),\n",
    "        value = as.numeric(unlist(value))\n",
    "    ) %>%\n",
    "    select(distribution, method, percent_censoring, value)\n",
    "\n",
    "    # sanity check \n",
    "    print(data)\n",
    "\n",
    "    # plot our result!\n",
    "    p1 <- ggplot(data, aes(x = percent_censoring, y = value, color = distribution, shape = method)) +\n",
    "    geom_point(size = 3, alpha = 0.6) +  \n",
    "    labs(\n",
    "        title = \"Scatter Plot časových výsledků\",\n",
    "        x = \"Míra Cenzorování[%]\",\n",
    "        y = \"Čas[s]\",\n",
    "        color = \"Rozdělení dat\",\n",
    "        shape = \"Metoda\"\n",
    "    ) +\n",
    "    theme_minimal() +\n",
    "    scale_color_brewer(palette = \"Set1\") +  \n",
    "    theme(\n",
    "        legend.position = \"right\",\n",
    "        legend.title = element_text(size = 12),\n",
    "        legend.text = element_text(size = 10)\n",
    "    )\n",
    "    ggsave(filename = paste0(\"Time_result_100\", \".png\"), plot = p1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6742d9-911e-4ae1-ba54-b8b15e1c4047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test on experiment on 100 observations\n",
    "results <- readRDS(\"results_100_.rds\")\n",
    "time_results <- readRDS(\"time_results_100_.rds\")\n",
    "estimates <- readRDS(\"estimates_sim_100_.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e08a0-3364-4a45-a841-44d7ec628f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time(time_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e481d-81db-4e65-acef-78cd22ffa5d7",
   "metadata": {},
   "source": [
    "### New simulation config\n",
    "Lets focus now on methods \"gehan-heller\" and \"gehan-poly\". We are interested in effect of different optimalization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054c57f-9b10-40ac-9b0e-5ad4d521662c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_coefficients <- c(1,1,1)\n",
    "error_types <- c(\"normal\") # use only normal distribution now, other distribution give us the similar results\n",
    "methods <- c(\"gehan-poly\", \"gehan-heller\")\n",
    "censoring <- c(25,50,90) # leave 0 percent censoring now and focus only on censored data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e512e08-ec99-48f1-b428-e6e292fa6ec8",
   "metadata": {},
   "source": [
    "### Different optimalization algorithms simulation\n",
    "The function expect three parameters\n",
    "<ul>\n",
    "    <li>n_simulations=number of simulations</li>\n",
    "    <li>sample_size=number of observations in dataset</li>\n",
    "    <li>alg=optimalization algorithm</li>\n",
    "</ul>\n",
    "\n",
    "The optimalization algorithm could be chosen from any available algorithms in package optimx, see documentation for more information https://cran.r-project.org/web/packages/optimx/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24033de9-da8a-4cfa-a5a4-cd9c896712ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation_for_gehans <- function(n_simulations, sample_size, alg)\n",
    "{\n",
    "    time_results <- list()\n",
    "    results <- list()\n",
    "    estimates_sim <- list()\n",
    "    fe_results <- list() # track number of function calls\n",
    "    convergence <- list() # track convergence status\n",
    "    ##\n",
    "    ## fe_results and convergence were not used in the final evaluation, because they didnt carry any interesting information\n",
    "    ##\n",
    "    n_simulations <- n_simulations\n",
    "    sample_size <- sample_size\n",
    "    for (error in error_types)\n",
    "    {\n",
    "      for (censor in censoring)\n",
    "          {\n",
    "              for (method in methods)\n",
    "              { \n",
    "                estimates <- matrix(NA, nrow = n_simulations, ncol = length(true_coefficients))\n",
    "                times <- numeric(n_simulations) # To store elapsed time\n",
    "                fe_calls <- numeric(n_simulations) # To store function calls  \n",
    "                convergence_calls <- numeric(n_simulations)\n",
    "\n",
    "                for (i in 1:n_simulations)\n",
    "                {\n",
    "                  # Generate data\n",
    "                  set.seed(seeds[i])\n",
    "\n",
    "                  censorNEW <- NaN\n",
    "                  \n",
    "                  if(censor == 0) {censorNEW <- -1}\n",
    "                  if(censor == 25){censorNEW <- 100}\n",
    "                  if(censor == 50) {censorNEW <- 30}\n",
    "                  if(censor == 90) {censorNEW <- 3}\n",
    "\n",
    "                  data <- datgen_model1(n = sample_size, error = error, censor = censorNEW)\n",
    "\n",
    "                  # Measure time of model fitting\n",
    "                  time_taken <- system.time({\n",
    "                    fit <- aftsem(Surv(log(data$Time), data$status) ~ data$x1 + data$x2 + data$x3, method = method, control = list(use.grad = FALSE, optimx.alg = alg,variance.estimation = FALSE, gehan_eps = 10^-6))\n",
    "                    # Adjust this line based on how you extract estimates\n",
    "                    estimates[i, ] <- c(fit$beta)\n",
    "                    fe_calls[i] <- fit$fe\n",
    "                    convergence_calls[i] <- fit$converged\n",
    "                  })\n",
    "\n",
    "                  times[i] <- time_taken[3]\n",
    "                }\n",
    "\n",
    "                bias <- colMeans(estimates) - true_coefficients\n",
    "                mse <- colMeans((estimates - true_coefficients)^2)\n",
    "                avg_fe_calls <- mean(fe_calls)\n",
    "                avg_time <- mean(times)\n",
    "                succesive_convergence <- sum(convergence_calls[convergence_calls == TRUE])\n",
    "\n",
    "                results[[paste(error, method, censor, sep = \"_\")]] <- list(bias = bias, mse = mse)\n",
    "                time_results[[paste(error, method, censor, sep = \"_\")]] <- avg_time\n",
    "                fe_results[[paste(error, method, censor, sep = \"_\")]] <- avg_fe_calls\n",
    "                estimates_sim[[paste(error, method, censor, sep = \"_\")]] <- estimates\n",
    "                convergence[[paste(error, method, censor, sep = \"_\")]] <- succesive_convergence\n",
    "              }\n",
    "        }\n",
    "    }\n",
    "    saveRDS(time_results, paste(\"time_results\",alg,sample_size, \".rds\", sep = \"_\"))\n",
    "    saveRDS(results, paste(\"results\",alg,sample_size,\".rds\", sep = \"_\"))\n",
    "    saveRDS(estimates_sim, paste(\"estimates_sim\",alg,sample_size,\".rds\", sep = \"_\"))\n",
    "    saveRDS(fe_results, paste(\"fe_results\",alg,sample_size,\".rds\",sep = \"_\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99640185-6660-45d5-bdab-cf801f99b9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_simulation_for_gehans(100,800,\"L-BFGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258c947-4e07-4dbb-8596-1387e7677942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "#tr <- readRDS(\"time_results_Nelder-Mead_800_.rds\")\n",
    "#r <- readRDS(\"results_Nelder-Mead_800_.rds\")\n",
    "#es <- readRDS(\"estimates_sim_BFGS_400_.rds\")\n",
    "#fe_r <- readRDS(\"fe_results_L-BFGS_400_.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ba869-8f00-47c9-8325-eec083d9a1c3",
   "metadata": {},
   "source": [
    "### See the results\n",
    "This summary dataframe has the same structure as the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967669a-ab73-49c5-b1f1-8b32e17a2023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df <- do.call(rbind, lapply(names(r), function(name) {\n",
    "  data.frame(\n",
    "    Scenario = name,\n",
    "    Bias = r[[name]]$bias,\n",
    "    MSE = r[[name]]$mse,\n",
    "    Avg_Time = tr[[name]]\n",
    "  )\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d77e2-5293-48a4-acfb-f421b1ffd0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793defc-53d5-48f4-a69a-5129f6dec595",
   "metadata": {},
   "source": [
    "### New simulation config\n",
    "We are now focusing on impact of initial beta estimation. User of package <b>aftsem</b> can choose three different initial beta estimations: gehan, lm(ordinary least squares solution) or custom numeric vector (in this simulation case it is vector of zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e815f-e10b-4274-950d-757f9b0aeeda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bb = c(\"zero\",\"lm\",\"gehan\")\n",
    "censoring <- c(25,50,90) # again not include scenario with 0 censoring\n",
    "error_types <- c(\"normal\",\"extreme\",\"logistic\")\n",
    "methods <- c(\"gehan-poly\", \"gehan-heller\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80254676-578f-4f76-93d8-c28e0d787040",
   "metadata": {},
   "source": [
    "### Different initial beta guess simulation\n",
    "The function takes two parameters\n",
    "<ul>\n",
    "    <li>n_simulations=number of simulations</li>\n",
    "    <li>sample_size=number of observations of data</li>\n",
    "</ul>\n",
    "The simulation again track fe and convergence results, however they are also not used in thesis evaluation, because i didnt found them interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d09bf9-bfd5-4a1b-838e-14b58a02d36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_simulations_for_binit <- function(n_simulations, sample_size)\n",
    "{\n",
    "    time_results <- list()\n",
    "    results <- list()\n",
    "    estimates_sim <- list()\n",
    "    fe_results <- list()\n",
    "    convergence <- list()\n",
    "    n_simulations <- n_simulations\n",
    "    sample_size <- sample_size\n",
    "    for (error in error_types)\n",
    "    {\n",
    "      for (censor in censoring)\n",
    "          {\n",
    "              for (method in methods)\n",
    "              {\n",
    "                \n",
    "                for (b in bb)\n",
    "                {\n",
    "                    estimates <- matrix(NA, nrow = n_simulations, ncol = length(true_coefficients))\n",
    "                    times <- numeric(n_simulations) # To store elapsed time\n",
    "                    fe_calls <- numeric(n_simulations) # To store function calls  \n",
    "                    convergence_calls <- numeric(n_simulations)\n",
    "\n",
    "                    for (i in 1:n_simulations)\n",
    "                    {\n",
    "                      # Generate data\n",
    "                      set.seed(seeds[i])\n",
    "\n",
    "                      censorNEW <- NaN\n",
    "                  \n",
    "                      if(censor == 0) {censorNEW <- -1}\n",
    "                      if(censor == 25){censorNEW <- 100}\n",
    "                      if(censor == 50) {censorNEW <- 30}\n",
    "                      if(censor == 90) {censorNEW <- 3}\n",
    "\n",
    "                      data <- datgen_model1(n = sample_size, error = error, censor = censorNEW)\n",
    "                      binit_value <- b  \n",
    "                      if (binit_value == \"zero\")\n",
    "                      {\n",
    "                          binit_value = rep(0,3)\n",
    "                      }\n",
    "\n",
    "                      # Measure time of model fitting\n",
    "                      time_taken <- system.time({\n",
    "                        fit <- aftsem(Surv(log(data$Time), data$status) ~ data$x1 + data$x2 + data$x3, method = method, binit = binit_value, control = list(use.grad = FALSE, optimx.alg = \"BFGS\",variance.estimation = FALSE, gehan_eps = 10^-6, quantile.method = \"br\"))\n",
    "                        # Adjust this line based on how you extract estimates\n",
    "                        estimates[i, ] <- c(fit$beta)\n",
    "                        fe_calls[i] <- fit$fe\n",
    "                        convergence_calls[i] <- fit$converged\n",
    "                      })\n",
    "\n",
    "                      # Store elapsed time\n",
    "                      times[i] <- time_taken[3]\n",
    "                  \n",
    "                    }\n",
    "\n",
    "                \n",
    "                bias <- colMeans(estimates) - true_coefficients\n",
    "                mse <- colMeans((estimates - true_coefficients)^2)\n",
    "                avg_fe_calls <- mean(fe_calls)\n",
    "                avg_time <- mean(times)\n",
    "                succesive_convergence <- sum(convergence_calls[convergence_calls == TRUE])\n",
    "\n",
    "                \n",
    "                results[[paste(error, method, censor, b, sep = \"_\")]] <- list(bias = bias, mse = mse)\n",
    "                time_results[[paste(error, method, censor, b, sep = \"_\")]] <- avg_time\n",
    "                fe_results[[paste(error, method, censor, b, sep = \"_\")]] <- avg_fe_calls\n",
    "                estimates_sim[[paste(error, method, censor, b, sep = \"_\")]] <- estimates\n",
    "                convergence[[paste(error, method, censor, b, sep = \"_\")]] <- succesive_convergence\n",
    "              }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    saveRDS(time_results, paste(\"time_results3\",\"binit\", \".rds\", sep = \"_\"))\n",
    "    saveRDS(results, paste(\"results3\",\"binit\",\".rds\", sep = \"_\"))\n",
    "    saveRDS(estimates_sim, paste(\"estimates_sim3\",\"binit\",\".rds\", sep = \"_\"))\n",
    "    saveRDS(fe_results, paste(\"fe_results3\",\"binit\",\".rds\",sep = \"_\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca36ed8-749c-4378-8fc4-db7578d9c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulations_for_binit(n_simulations = 500,sample_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67692302-dd47-4109-9682-4b5f27334be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check, check the simulated data\n",
    "#rrr <- readRDS(\"results2_binit_.rds\")\n",
    "#ttt <- readRDS(\"time_results2_binit_.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57752d1b-0117-43a4-a467-1a102f7c2ecb",
   "metadata": {},
   "source": [
    "### Create dataframe of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9aa0f0-adef-44de-a712-dd2fd3239000",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df <- do.call(rbind, lapply(names(rrr), function(name) {\n",
    "  data.frame(\n",
    "    Scenario = name,\n",
    "    Bias = rrr[[name]]$bias,\n",
    "    MSE = rrr[[name]]$mse,\n",
    "    Avg_Time = ttt[[name]]\n",
    "  )\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f90d1f-3da2-4af6-a2ff-d1ec460d5bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows = 150, repr.matrix.max.cols = 10)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e803486-9aa3-4f6c-8416-5214bf0b1479",
   "metadata": {},
   "source": [
    "### New simulation config\n",
    "We are interested in effect of choosing different quantile regression algorithms in package quatreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9c9d1-aa35-4615-9502-23ba7ef34f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "censoring <- c(25,50,90)\n",
    "error_types <- c(\"normal\",\"extreme\",\"logistic\")\n",
    "methods <- c(\"gehan\")\n",
    "algs <- c(\"fn\",\"pfn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c0d631-11e3-4e40-aa3a-df833f4ac878",
   "metadata": {},
   "source": [
    "### Different quantile regression algorithms\n",
    "The function has the same structure as previous and takes two parameters\n",
    "<ul>\n",
    "    <li>n_simulations=number of simulations</li>\n",
    "    <li>sample_size=number of observations of each dataset</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c1e49-6e39-4565-9a65-3219cde4d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulations_for_median_reg <- function(n_simulations, sample_size)\n",
    "{\n",
    "    time_results <- list()\n",
    "    results <- list()\n",
    "    estimates_sim <- list()\n",
    "    n_simulations <- n_simulations\n",
    "    sample_size <- sample_size\n",
    "    \n",
    "    for (error in error_types)\n",
    "    {\n",
    "      for (censor in censoring)\n",
    "          {\n",
    "              for (a in algs)\n",
    "              {\n",
    "                estimates <- matrix(NA, nrow = n_simulations, ncol = length(true_coefficients))\n",
    "                times <- numeric(n_simulations) # To store elapsed time\n",
    "\n",
    "                for (i in 1:n_simulations)\n",
    "                {\n",
    "                     # Generate data\n",
    "                     set.seed(seeds[i])\n",
    "\n",
    "                    censorNEW <- NaN\n",
    "                  \n",
    "                    if(censor == 0) {censorNEW <- -1}\n",
    "                    if(censor == 25){censorNEW <- 100}\n",
    "                    if(censor == 50) {censorNEW <- 30}\n",
    "                    if(censor == 90) {censorNEW <- 3}\n",
    "\n",
    "                    data <- datgen_model1(n = sample_size, error = error, censor = censorNEW)\n",
    "\n",
    "                    time_taken <- system.time({\n",
    "                       fit <- aftsem(Surv(log(data$Time), data$status) ~ data$x1 + data$x2 + data$x3, method = \"gehan\", control = list(quantile.method = a))\n",
    "                        estimates[i, ] <- c(fit$beta)\n",
    "                      })\n",
    "\n",
    "                      \n",
    "                      times[i] <- time_taken[3]\n",
    "                  \n",
    "                    }\n",
    "\n",
    "                \n",
    "                bias <- colMeans(estimates) - true_coefficients\n",
    "                mse <- colMeans((estimates - true_coefficients)^2)\n",
    "                avg_time <- mean(times)\n",
    "\n",
    "                \n",
    "                results[[paste(error, a, censor, sep = \"_\")]] <- list(bias = bias, mse = mse)\n",
    "                time_results[[paste(error, a, censor, sep = \"_\")]] <- avg_time\n",
    "                estimates_sim[[paste(error, a, censor, sep = \"_\")]] <- estimates\n",
    "              }\n",
    "        }\n",
    "    }\n",
    "    saveRDS(time_results, paste(\"time_results\",\"median\", \".rds\", sep = \"_\"))\n",
    "    saveRDS(results, paste(\"results\",\"median\",\".rds\", sep = \"_\"))\n",
    "    saveRDS(estimates_sim, paste(\"estimates_sim\",\"median\",\".rds\", sep = \"_\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49842b-a363-4d6b-bed6-80a507178e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulations_for_median_reg(300,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8c808-b0f5-4cc5-9a47-029051dd4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "#tt <- readRDS(\"time_results_400_.rds\")\n",
    "#tm <- readRDS(\"time_results_median_.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c45a63-cac2-4cda-a7ce-2bde69238de2",
   "metadata": {},
   "source": [
    "### See the results in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05214ab0-8257-4d3b-8054-c94de4291b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df <- do.call(rbind, lapply(names(rm), function(name) {\n",
    "  data.frame(\n",
    "    Scenario = name,\n",
    "    Bias = rm[[name]]$bias,\n",
    "    MSE = rm[[name]]$mse,\n",
    "    Avg_Time = tm[[name]]\n",
    "  )\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f7199-8aa3-48b6-91c6-27c25f3d6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df56235-f3eb-444c-a52f-475758f801e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_items <- tt[grep(\"_(gehan)_(25|50|90)$\", names(tt))]\n",
    "selected_names <- names(selected_items)\n",
    "names(selected_items) <- sub(\"gehan\", \"br\", selected_names)\n",
    "print(selected_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c120601-7191-428c-ba69-dbbba03eca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm <- c(tm, selected_items)\n",
    "tm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d18516-217a-48af-8ea8-dc1ef77cbf1e",
   "metadata": {},
   "source": [
    "### Plot the time results of different median regression algorithms\n",
    "The function is basically the same as previous time plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140f74a-7ccf-4099-aa79-e75690a8d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_median_reg <- function(data_list)\n",
    "{    \n",
    "    # first convert our list to dataframe using pipes\n",
    "    data <- enframe(data_list, name = \"metric\", value = \"value\") %>%\n",
    "    mutate(\n",
    "        metric = as.character(metric),\n",
    "        distribution = gsub(\"([a-z]+)_.*\", \"\\\\1\", metric),\n",
    "        method = gsub(\"[a-z]+_(.*?)(_\\\\d+)?$\", \"\\\\1\", metric),\n",
    "        percent_censoring = as.numeric(gsub(\".*_(\\\\d+)$\", \"\\\\1\", metric)),\n",
    "        value = as.numeric(unlist(value))\n",
    "    ) %>%\n",
    "    select(distribution, method, percent_censoring, value)\n",
    "\n",
    "    # sanity check \n",
    "    print(data)\n",
    "\n",
    "    # plot our result!\n",
    "    p1 <- ggplot(data, aes(x = percent_censoring, y = value, color = distribution, shape = method)) +\n",
    "    geom_point(size = 3, alpha = 0.6) +  \n",
    "    labs(\n",
    "        title = \"Scatter Plot časových výsledků u algoritmů mediánové regrese\",\n",
    "        x = \"Míra Cenzorování[%]\",\n",
    "        y = \"Čas[s]\",\n",
    "        color = \"Rozdělení dat\",\n",
    "        shape = \"Algoritmus\"\n",
    "    ) +\n",
    "    theme_minimal() +\n",
    "    scale_color_brewer(palette = \"Set1\") +  \n",
    "    theme(\n",
    "        legend.position = \"right\",\n",
    "        legend.title = element_text(size = 12),\n",
    "        legend.text = element_text(size = 10)\n",
    "    )\n",
    "    ggsave(filename = paste0(\"median_400\", \".png\"), plot = p1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9350f8-d90b-4ef8-a448-cb69614b4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_median_reg(tm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
